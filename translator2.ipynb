{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOOOxd4l65Y+58StpHPLlRR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eissana/translator/blob/master/translator2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchtext==0.6"
      ],
      "metadata": {
        "id": "tHgQZOIQhTks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade spacy"
      ],
      "metadata": {
        "id": "y03iOMhOhU5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.data import BucketIterator\n",
        "from torchtext.data import Field\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import spacy\n",
        "import numpy as np\n",
        "import yaml"
      ],
      "metadata": {
        "id": "efAxiX6lgzeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss(logits, y, ignore_index):\n",
        "    \"\"\"\n",
        "    Computes cross-entropy loss, given logits and labels.\n",
        "    \"\"\"\n",
        "    B, T, C = logits.shape\n",
        "    # F.cross_entropy expects size C, (B, C), or (B, C, ...)\n",
        "    # logits shape is (B, T, C), so we flatten the first two dimensions.\n",
        "    return F.cross_entropy(\n",
        "        logits.view(B * T, C), y.reshape(B * T), ignore_index=ignore_index\n",
        "    )\n",
        "    # loss_fn = nn.CrossEntropyLoss(ignore_index=tgt_pad_index)\n",
        "    # return loss_fn(logits.view(B*T, C), y.reshape(B*T))\n",
        "\n",
        "\n",
        "def text2tokens(text, tokenizer):\n",
        "    tokens = [Preprocessor.INIT_TOKEN]\n",
        "    tokens.extend([t.text.lower() for t in tokenizer(text)])\n",
        "    tokens.append(Preprocessor.EOS_TOKEN)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def src2target(tokens, model, preprocessor, block_size, device):\n",
        "    \"\"\"\n",
        "    Gets source language tokens, calls model to translate them, and returns\n",
        "    target tokens.\n",
        "    \"\"\"\n",
        "    token_ids = [preprocessor.src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    x = torch.tensor(token_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    sos = preprocessor.tgt_field.vocab.stoi[Preprocessor.INIT_TOKEN]\n",
        "    eos = preprocessor.tgt_field.vocab.stoi[Preprocessor.EOS_TOKEN]\n",
        "\n",
        "    y = torch.tensor([[sos]], dtype=torch.long, device=device)\n",
        "\n",
        "    for _ in range(block_size):\n",
        "        with torch.no_grad():\n",
        "            logits = model(x, y)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        scores = F.softmax(logits, dim=-1)\n",
        "        next_token = scores.multinomial(1)\n",
        "        # next_token = logits.argmax(dim=-1).unsqueeze(0)\n",
        "\n",
        "        if next_token.item() == eos:\n",
        "            break\n",
        "\n",
        "        y = torch.cat((y, next_token), dim=-1)\n",
        "\n",
        "    y = y.view(-1)\n",
        "    y = [preprocessor.tgt_field.vocab.itos[t] for t in y]\n",
        "\n",
        "    return y[1:]\n",
        "\n",
        "\n",
        "def translate(text, model, preprocessor, block_size, device):\n",
        "    src_tokens = text2tokens(text, preprocessor.src_spacy.tokenizer)\n",
        "    tgt_tokens = src2target(src_tokens, model, preprocessor, block_size, device)\n",
        "    return \" \".join(tgt_tokens)\n",
        "\n",
        "\n",
        "def bleu(data, model, preprocessor, block_size, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = example.src\n",
        "        trg = example.trg\n",
        "        prediction = src2target(src, model, preprocessor, block_size, device)\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n"
      ],
      "metadata": {
        "id": "O-PFAf6Wh-Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "s5iyGpM8jl9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%python3 -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "ThsnOhMojnis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh multi30k.sh"
      ],
      "metadata": {
        "id": "2XmKfU1PkAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor():\n",
        "    INIT_TOKEN = \"<init>\"\n",
        "    EOS_TOKEN = \"<eos>\"  # end of sentence\n",
        "\n",
        "    def __init__(self, spacy_names, exts, data_root, min_freq, max_size):\n",
        "        self.src_spacy = spacy.load(spacy_names[0])\n",
        "        self.tgt_spacy = spacy.load(spacy_names[1])\n",
        "\n",
        "        def src_tokenize(text):\n",
        "            return [t.text for t in self.src_spacy.tokenizer(text)]\n",
        "\n",
        "        def tgt_tokenize(text):\n",
        "            return [t.text for t in self.tgt_spacy.tokenizer(text)]\n",
        "\n",
        "        self.src_field = Field(\n",
        "            tokenize=src_tokenize,\n",
        "            init_token=self.INIT_TOKEN,\n",
        "            eos_token=self.EOS_TOKEN,\n",
        "            lower=True,\n",
        "        )\n",
        "        self.tgt_field = Field(\n",
        "            tokenize=tgt_tokenize,\n",
        "            init_token=self.INIT_TOKEN,\n",
        "            eos_token=self.EOS_TOKEN,\n",
        "            lower=True,\n",
        "        )\n",
        "\n",
        "        # Run the following command to download data:\n",
        "        # > sh multi30k.sh\n",
        "        self.train, self.val, self.test = Multi30k.splits(\n",
        "            exts=exts,\n",
        "            fields=(self.src_field, self.tgt_field),\n",
        "            root=data_root,  # data/multi30k/\n",
        "        )\n",
        "        self.src_field.build_vocab(self.train, max_size=max_size, min_freq=min_freq)\n",
        "        self.tgt_field.build_vocab(self.train, max_size=max_size, min_freq=min_freq)\n"
      ],
      "metadata": {
        "id": "X64qkAaph4V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        src_pad_idx,\n",
        "        tgt_pad_idx,\n",
        "        block_size,\n",
        "        device,\n",
        "        embedding_dim,\n",
        "        nhead,\n",
        "        dim_feedforward,\n",
        "        dropout,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.tgt_pad_idx = tgt_pad_idx\n",
        "\n",
        "        self.src_emb = nn.Embedding(src_vocab_size, embedding_dim)\n",
        "        self.src_pos = nn.Embedding(block_size, embedding_dim)\n",
        "\n",
        "        self.tgt_emb = nn.Embedding(tgt_vocab_size, embedding_dim)\n",
        "        self.tgt_pos = nn.Embedding(block_size, embedding_dim)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embedding_dim,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.proj = nn.Linear(embedding_dim, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        _, srcT = src.shape\n",
        "        src_positions = torch.arange(srcT).unsqueeze(0).to(self.device)\n",
        "        src_out = self.src_emb(src) + self.src_pos(src_positions)\n",
        "        src_out = self.dropout(src_out)\n",
        "\n",
        "        _, tgtT = tgt.shape\n",
        "        tgt_positions = torch.arange(tgtT).unsqueeze(0).to(self.device)\n",
        "        tgt_out = self.tgt_emb(tgt) + self.tgt_pos(tgt_positions)\n",
        "        tgt_out = self.dropout(tgt_out)\n",
        "\n",
        "        # Avoiding unnecessary computation on padded text\n",
        "        src_key_padding_mask = src == self.src_pad_idx\n",
        "        tgt_key_padding_mask = tgt == self.tgt_pad_idx\n",
        "\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgtT).to(self.device)\n",
        "        out = self.transformer(\n",
        "            src=src_out,\n",
        "            tgt=tgt_out,\n",
        "            src_key_padding_mask=src_key_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "        )\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "jqUOrtbBkpTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"running on {device}\")\n",
        "model_filename = \"models/model.pt\"\n",
        "\n",
        "example_text = \"Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\"\n",
        "\n",
        "load_model = True\n",
        "save_model = True\n",
        "\n",
        "params = {\n",
        "    \"epochs\": 10,\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"batch_size\": 32,\n",
        "    \"embedding_dim\": 512,\n",
        "    \"nhead\": 8,\n",
        "    \"num_encoder_layers\": 3,\n",
        "    \"num_decoder_layers\": 3,\n",
        "    \"dropout\": 0.1,\n",
        "    \"block_size\": 100,\n",
        "    \"dim_feedforward\": 4,\n",
        "}\n",
        "\n",
        "losses = {\n",
        "    \"train\": [],\n",
        "    \"val\": [],\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyBKOEFAnYQO",
        "outputId": "0748f4ec-fa9b-4832-d1f5-a321545c09cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pp = Preprocessor(\n",
        "    spacy_names=(\"de_core_news_sm\", \"en_core_web_sm\"),\n",
        "    exts=(\".de\", \".en\"),\n",
        "    data_root=\"data\",\n",
        "    min_freq=2,\n",
        "    max_size=10000,\n",
        ")\n",
        "\n",
        "src_vocab_size = len(pp.src_field.vocab)\n",
        "tgt_vocab_size = len(pp.tgt_field.vocab)\n",
        "\n",
        "src_pad_idx = pp.src_field.vocab.stoi[pp.src_field.pad_token]\n",
        "tgt_pad_idx = pp.tgt_field.vocab.stoi[pp.tgt_field.pad_token]\n",
        "\n",
        "train_iter, val_iter, _ = BucketIterator.splits(\n",
        "    datasets=(pp.train, pp.val, pp.test),\n",
        "    batch_size=params[\"batch_size\"],\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.src),\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "model = Transformer(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    num_encoder_layers=params[\"num_encoder_layers\"],\n",
        "    num_decoder_layers=params[\"num_decoder_layers\"],\n",
        "    src_pad_idx=src_pad_idx,\n",
        "    tgt_pad_idx=tgt_pad_idx,\n",
        "    block_size=params[\"block_size\"],\n",
        "    device=device,\n",
        "    embedding_dim=params[\"embedding_dim\"],\n",
        "    nhead=params[\"nhead\"],\n",
        "    dim_feedforward=params[\"dim_feedforward\"],\n",
        "    dropout=params[\"dropout\"],\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"learning_rate\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10\n",
        ")\n",
        "\n",
        "if load_model:\n",
        "    state = torch.load(model_filename)\n",
        "\n",
        "    model.load_state_dict(state[\"model\"])\n",
        "    optimizer.load_state_dict(state[\"optimizer\"])\n",
        "    scheduler.load_state_dict(state[\"scheduler\"])\n",
        "\n",
        "num_params = sum([p.nelement() for p in model.parameters()])\n",
        "print(f\"\\nmodel parameters: {num_params}\")\n",
        "print(f\"\\n{params=}\")\n",
        "\n",
        "print(f\"\\nexample text to trasnlate: {example_text}\")\n",
        "\n",
        "answer = input(\"\\nwould you like to proceed to training? (y/n): \")\n",
        "if answer.lower() in {\"y\", \"yes\"}:\n",
        "    for epoch in range(params[\"epochs\"]):\n",
        "        print(f\"epoch {epoch} / {params['epochs']}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            translated_text = translate(\n",
        "                example_text,\n",
        "                model,\n",
        "                pp,\n",
        "                params[\"block_size\"],\n",
        "                device,\n",
        "            )\n",
        "            print(f\"translated example text:\\n{translated_text}\")\n",
        "\n",
        "            batch_loss = []\n",
        "            for batch in val_iter:\n",
        "                src = batch.src.T.to(device)\n",
        "                tgt = batch.trg.T.to(device)\n",
        "\n",
        "                logits = model(src, tgt[:, :-1])\n",
        "                vloss = get_loss(\n",
        "                    logits,\n",
        "                    tgt[:, 1:],\n",
        "                    ignore_index=pp.tgt_field.vocab.stoi[pp.tgt_field.pad_token],\n",
        "                  )\n",
        "                batch_loss.append(vloss.item())\n",
        "\n",
        "            losses['val'].extend(batch_loss)\n",
        "\n",
        "        model.train()\n",
        "        batch_loss = []\n",
        "        for batch in train_iter:\n",
        "            src = batch.src.T.to(device)\n",
        "            tgt = batch.trg.T.to(device)\n",
        "\n",
        "            logits = model(src, tgt[:, :-1])\n",
        "            loss = get_loss(\n",
        "                logits,\n",
        "                tgt[:, 1:],\n",
        "                ignore_index=pp.tgt_field.vocab.stoi[pp.tgt_field.pad_token],\n",
        "            )\n",
        "            batch_loss.append(loss.item())\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "        losses['train'].extend(batch_loss)\n",
        "        if save_model:\n",
        "            checkpoint = {\n",
        "                \"model\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "                \"scheduler\": scheduler.state_dict(),\n",
        "            }\n",
        "            torch.save(checkpoint, model_filename)\n",
        "\n",
        "        scheduler.step(np.mean(batch_loss))\n",
        "\n",
        "print(f\"\\ncomputing bleu score...\")\n",
        "score = bleu(pp.test[:100], model, pp, params[\"block_size\"], device) * 100\n",
        "print(f\"bleu score: {score:0.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veu-pAsniL5_",
        "outputId": "c8204011-1005-46d3-84c6-9edacabaf1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "model parameters: 19664157\n",
            "\n",
            "params={'epochs': 10, 'learning_rate': 0.0003, 'batch_size': 32, 'embedding_dim': 512, 'nhead': 8, 'num_encoder_layers': 3, 'num_decoder_layers': 3, 'dropout': 0.1, 'block_size': 100, 'dim_feedforward': 4}\n",
            "\n",
            "example text to trasnlate: Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n",
            "\n",
            "would you like to proceed to training? (y/n): y\n",
            "epoch 0 / 10\n",
            "translated example text:\n",
            " two young white men are outside near each other in the space .\n",
            "epoch 1 / 10\n",
            "translated example text:\n",
            " two young white men are outside near many bushes .\n",
            "epoch 2 / 10\n",
            "translated example text:\n",
            " two young white men are outside while behind them .\n",
            "epoch 3 / 10\n",
            "translated example text:\n",
            " two young white men are outside near many bushes .\n",
            "epoch 4 / 10\n",
            "translated example text:\n",
            " two young white males are outside near many bushes .\n",
            "epoch 5 / 10\n",
            "translated example text:\n",
            " two young white males are outside in the outdoors near them .\n",
            "epoch 6 / 10\n",
            "translated example text:\n",
            " two young white man are outside near many bushes .\n",
            "epoch 7 / 10\n",
            "translated example text:\n",
            " two young white males are outside near many people .\n",
            "epoch 8 / 10\n",
            "translated example text:\n",
            " two young white males are outside , there are outside near many bushes .\n",
            "epoch 9 / 10\n",
            "translated example text:\n",
            " two young white males are outside in the air near them .\n",
            "\n",
            "computing bleu score...\n",
            "bleu score: 14.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"loss of a random model: {np.log(len(pp.tgt_field.vocab))}\")\n",
        "print(f\"final training loss: {np.mean(losses['train'])}\")\n",
        "print(f\"final validation loss: {np.mean(losses['val'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsasU9U__npN",
        "outputId": "5a52a09e-35ec-45d9-d0ce-f7d9a131c25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss of a random model: 8.681520484837913\n",
            "final training loss: 0.7463156780636692\n",
            "final validation loss: 1.7903295058757067\n"
          ]
        }
      ]
    }
  ]
}